import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import cv2
import numpy as np
from PIL import Image, ImageTk, ImageFilter, ImageEnhance
import os
import threading
from skimage import restoration, measure, filters, morphology, segmentation
from scipy import ndimage, signal
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import warnings
warnings.filterwarnings('ignore')

class AdvancedImageRestorationApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Ch∆∞∆°ng tr√¨nh Kh√¥i ph·ª•c ·∫¢nh AI N√¢ng cao")
        self.root.geometry("1600x1000")
        
        # Bi·∫øn l∆∞u tr·ªØ ·∫£nh
        self.original_image = None
        self.processed_image = None
        self.current_image_path = None
        self.processing_steps = []
        
        # Thi·∫øt l·∫≠p giao di·ªán
        self.setup_ui()
        
    def setup_ui(self):
        # Frame ch√≠nh
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Frame ƒëi·ªÅu khi·ªÉn
        control_frame = ttk.LabelFrame(main_frame, text="ƒêi·ªÅu khi·ªÉn", padding="10")
        control_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # N√∫t ch·ªçn ·∫£nh
        ttk.Button(control_frame, text="Ch·ªçn ·∫¢nh", command=self.load_image).grid(row=0, column=0, padx=(0, 10))
        ttk.Button(control_frame, text="L∆∞u ·∫¢nh", command=self.save_image).grid(row=0, column=1, padx=(0, 10))
        ttk.Button(control_frame, text="So s√°nh Chi ti·∫øt", command=self.detailed_comparison).grid(row=0, column=2, padx=(0, 10))
        ttk.Button(control_frame, text="X·ª≠ l√Ω H√†ng lo·∫°t", command=self.batch_process).grid(row=0, column=3, padx=(0, 10))
        
        # Frame t√πy ch·ªçn x·ª≠ l√Ω n√¢ng cao
        processing_frame = ttk.LabelFrame(main_frame, text="X·ª≠ l√Ω AI N√¢ng cao", padding="10")
        processing_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Preset modes
        ttk.Label(processing_frame, text="Ch·∫ø ƒë·ªô:").grid(row=0, column=0, sticky=tk.W)
        self.preset_mode = tk.StringVar(value="T·ª± ƒë·ªông")
        mode_combo = ttk.Combobox(processing_frame, textvariable=self.preset_mode, width=15,
                                 values=["T·ª± ƒë·ªông", "·∫¢nh c≈©", "T√†i li·ªáu", "·∫¢nh ch√¢n dung", "T√πy ch·ªânh"])
        mode_combo.grid(row=0, column=1, sticky=tk.W)
        mode_combo.bind('<<ComboboxSelected>>', self.on_preset_change)
        
        # AI Kh·ª≠ nhi·ªÖu
        ttk.Label(processing_frame, text="AI Kh·ª≠ nhi·ªÖu:").grid(row=1, column=0, sticky=tk.W)
        self.ai_denoise_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(processing_frame, variable=self.ai_denoise_var).grid(row=1, column=1, sticky=tk.W)
        
        ttk.Label(processing_frame, text="C∆∞·ªùng ƒë·ªô:").grid(row=1, column=2, padx=(20, 5))
        self.ai_denoise_strength = tk.DoubleVar(value=0.8)
        ttk.Scale(processing_frame, from_=0.1, to=2.0, variable=self.ai_denoise_strength, 
                 orient=tk.HORIZONTAL, length=120).grid(row=1, column=3)
        
        # Kh·ª≠ m·ªù n√¢ng cao
        ttk.Label(processing_frame, text="Kh·ª≠ m·ªù AI:").grid(row=2, column=0, sticky=tk.W)
        self.ai_deblur_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(processing_frame, variable=self.ai_deblur_var).grid(row=2, column=1, sticky=tk.W)
        
        ttk.Label(processing_frame, text="Kernel:").grid(row=2, column=2, padx=(20, 5))
        self.deblur_kernel = tk.StringVar(value="Adaptive")
        ttk.Combobox(processing_frame, textvariable=self.deblur_kernel, width=10,
                    values=["Adaptive", "Gaussian", "Motion", "Defocus"]).grid(row=2, column=3)
        
        # Super Resolution AI
        ttk.Label(processing_frame, text="Super Resolution:").grid(row=3, column=0, sticky=tk.W)
        self.super_res_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(processing_frame, variable=self.super_res_var).grid(row=3, column=1, sticky=tk.W)
        
        ttk.Label(processing_frame, text="T·ªâ l·ªá:").grid(row=3, column=2, padx=(20, 5))
        self.scale_factor = tk.StringVar(value="2x")
        ttk.Combobox(processing_frame, textvariable=self.scale_factor, width=10,
                    values=["2x", "3x", "4x"]).grid(row=3, column=3)
        
        # Kh√¥i ph·ª•c m√†u s·∫Øc
        ttk.Label(processing_frame, text="Kh√¥i ph·ª•c m√†u:").grid(row=4, column=0, sticky=tk.W)
        self.color_restore_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(processing_frame, variable=self.color_restore_var).grid(row=4, column=1, sticky=tk.W)
        
        ttk.Label(processing_frame, text="C∆∞·ªùng ƒë·ªô:").grid(row=4, column=2, padx=(20, 5))
        self.color_strength = tk.DoubleVar(value=1.2)
        ttk.Scale(processing_frame, from_=0.5, to=2.0, variable=self.color_strength, 
                 orient=tk.HORIZONTAL, length=120).grid(row=4, column=3)
        
        # Kh√¥i ph·ª•c c·∫•u tr√∫c
        ttk.Label(processing_frame, text="Kh√¥i ph·ª•c c·∫•u tr√∫c:").grid(row=5, column=0, sticky=tk.W)
        self.structure_restore_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(processing_frame, variable=self.structure_restore_var).grid(row=5, column=1, sticky=tk.W)
        
        ttk.Label(processing_frame, text="ƒê·ªô m·∫°nh:").grid(row=5, column=2, padx=(20, 5))
        self.structure_strength = tk.DoubleVar(value=0.6)
        ttk.Scale(processing_frame, from_=0.1, to=1.0, variable=self.structure_strength, 
                 orient=tk.HORIZONTAL, length=120).grid(row=5, column=3)
        
        # N√∫t x·ª≠ l√Ω
        process_btn = ttk.Button(processing_frame, text="üöÄ X·ª≠ l√Ω AI", command=self.process_image)
        process_btn.grid(row=6, column=0, columnspan=2, pady=10, sticky=(tk.W, tk.E))
        
        reset_btn = ttk.Button(processing_frame, text="üîÑ Reset", command=self.reset_parameters)
        reset_btn.grid(row=6, column=2, columnspan=2, pady=10, sticky=(tk.W, tk.E))
        
        # Progress bar v·ªõi th√¥ng tin
        self.progress = ttk.Progressbar(processing_frame, mode='determinate')
        self.progress.grid(row=7, column=0, columnspan=4, sticky=(tk.W, tk.E), pady=5)
        
        self.progress_label = ttk.Label(processing_frame, text="S·∫µn s√†ng")
        self.progress_label.grid(row=8, column=0, columnspan=4)
        
        # Frame hi·ªÉn th·ªã ·∫£nh
        image_frame = ttk.Frame(main_frame)
        image_frame.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # ·∫¢nh g·ªëc
        original_frame = ttk.LabelFrame(image_frame, text="·∫¢nh G·ªëc", padding="5")
        original_frame.grid(row=0, column=0, padx=(0, 5), sticky=(tk.W, tk.E, tk.N, tk.S))
        
        self.original_canvas = tk.Canvas(original_frame, width=750, height=500, bg='white')
        self.original_canvas.grid(row=0, column=0)
        
        # ·∫¢nh x·ª≠ l√Ω
        processed_frame = ttk.LabelFrame(image_frame, text="·∫¢nh Sau X·ª≠ l√Ω AI", padding="5")
        processed_frame.grid(row=0, column=1, padx=(5, 0), sticky=(tk.W, tk.E, tk.N, tk.S))
        
        self.processed_canvas = tk.Canvas(processed_frame, width=750, height=500, bg='white')
        self.processed_canvas.grid(row=0, column=0)
        
        # Th√¥ng tin ·∫£nh
        info_frame = ttk.LabelFrame(main_frame, text="Th√¥ng tin X·ª≠ l√Ω", padding="10")
        info_frame.grid(row=3, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(10, 0))
        
        self.info_text = tk.Text(info_frame, height=6, width=100)
        self.info_text.grid(row=0, column=0, sticky=(tk.W, tk.E))
        
        scrollbar = ttk.Scrollbar(info_frame, orient=tk.VERTICAL, command=self.info_text.yview)
        scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        self.info_text.configure(yscrollcommand=scrollbar.set)
        
        # C·∫•u h√¨nh grid weights
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        main_frame.rowconfigure(2, weight=1)
        image_frame.columnconfigure(0, weight=1)
        image_frame.columnconfigure(1, weight=1)
        image_frame.rowconfigure(0, weight=1)
        info_frame.columnconfigure(0, weight=1)
        
    def on_preset_change(self, event=None):
        """Thay ƒë·ªïi tham s·ªë theo preset"""
        mode = self.preset_mode.get()
        
        if mode == "·∫¢nh c≈©":
            self.ai_denoise_strength.set(1.2)
            self.color_strength.set(1.5)
            self.structure_strength.set(0.8)
            self.deblur_kernel.set("Gaussian")
            
        elif mode == "T√†i li·ªáu":
            self.ai_denoise_strength.set(0.6)
            self.color_strength.set(1.0)
            self.structure_strength.set(0.9)
            self.deblur_kernel.set("Adaptive")
            
        elif mode == "·∫¢nh ch√¢n dung":
            self.ai_denoise_strength.set(0.4)
            self.color_strength.set(1.3)
            self.structure_strength.set(0.5)
            self.deblur_kernel.set("Defocus")
            
        elif mode == "T·ª± ƒë·ªông":
            self.ai_denoise_strength.set(0.8)
            self.color_strength.set(1.2)
            self.structure_strength.set(0.6)
            self.deblur_kernel.set("Adaptive")
    
    def load_image(self):
        """T·∫£i ·∫£nh t·ª´ file"""
        file_path = filedialog.askopenfilename(
            title="Ch·ªçn ·∫£nh",
            filetypes=[("Image files", "*.jpg *.jpeg *.png *.bmp *.tiff *.webp")]
        )
        
        if file_path:
            try:
                self.current_image_path = file_path
                self.original_image = cv2.imread(file_path)
                self.original_image = cv2.cvtColor(self.original_image, cv2.COLOR_BGR2RGB)
                self.display_image(self.original_image, self.original_canvas)
                
                # Ph√¢n t√≠ch ·∫£nh t·ª± ƒë·ªông
                self.analyze_image()
                
                messagebox.showinfo("Th√†nh c√¥ng", "ƒê√£ t·∫£i ·∫£nh th√†nh c√¥ng!")
            except Exception as e:
                messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ t·∫£i ·∫£nh: {str(e)}")
    
    def analyze_image(self):
        """Ph√¢n t√≠ch ·∫£nh v√† ƒë∆∞a ra khuy·∫øn ngh·ªã"""
        if self.original_image is None:
            return
            
        h, w = self.original_image.shape[:2]
        gray = cv2.cvtColor(self.original_image, cv2.COLOR_RGB2GRAY)
        
        # T√≠nh to√°n c√°c ch·ªâ s·ªë ch·∫•t l∆∞·ª£ng
        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
        noise_score = np.std(gray)
        contrast_score = gray.std()
        brightness_score = gray.mean()
        
        info = f"=== PH√ÇN T√çCH ·∫¢NH ===\n"
        info += f"K√≠ch th∆∞·ªõc: {w}x{h}\n"
        info += f"ƒê·ªô m·ªù: {blur_score:.2f} {'(M·ªù)' if blur_score < 100 else '(S·∫Øc n√©t)'}\n"
        info += f"Nhi·ªÖu: {noise_score:.2f} {'(Nhi·ªÅu nhi·ªÖu)' if noise_score > 50 else '(√çt nhi·ªÖu)'}\n"
        info += f"T∆∞∆°ng ph·∫£n: {contrast_score:.2f} {'(Th·∫•p)' if contrast_score < 40 else '(T·ªët)'}\n"
        info += f"ƒê·ªô s√°ng: {brightness_score:.2f} {'(T·ªëi)' if brightness_score < 100 else '(S√°ng)' if brightness_score > 180 else '(V·ª´a)'}\n"
        
        # Khuy·∫øn ngh·ªã
        info += "\n=== KHUY·∫æN NGH·ªä ===\n"
        if blur_score < 100:
            info += "‚Ä¢ C·∫ßn kh·ª≠ m·ªù m·∫°nh\n"
        if noise_score > 50:
            info += "‚Ä¢ C·∫ßn kh·ª≠ nhi·ªÖu cao\n"
        if contrast_score < 40:
            info += "‚Ä¢ C·∫ßn tƒÉng t∆∞∆°ng ph·∫£n\n"
        if brightness_score < 100:
            info += "‚Ä¢ C·∫ßn tƒÉng ƒë·ªô s√°ng\n"
        
        self.info_text.delete(1.0, tk.END)
        self.info_text.insert(tk.END, info)
    
    def display_image(self, image, canvas):
        """Hi·ªÉn th·ªã ·∫£nh tr√™n canvas"""
        if image is None:
            return
            
        # Resize ·∫£nh ƒë·ªÉ fit canvas
        canvas_width = canvas.winfo_width()
        canvas_height = canvas.winfo_height()
        
        if canvas_width <= 1 or canvas_height <= 1:
            canvas_width, canvas_height = 750, 500
        
        h, w = image.shape[:2]
        scale = min(canvas_width/w, canvas_height/h)
        new_w, new_h = int(w*scale), int(h*scale)
        
        if len(image.shape) == 3:
            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            pil_image = Image.fromarray(resized)
        else:
            resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
            pil_image = Image.fromarray(resized).convert('RGB')
        
        photo = ImageTk.PhotoImage(pil_image)
        
        canvas.delete("all")
        canvas.create_image(canvas_width//2, canvas_height//2, anchor=tk.CENTER, image=photo)
        canvas.image = photo
    
    def advanced_ai_denoise(self, image):
        """Kh·ª≠ nhi·ªÖu AI ti√™n ti·∫øn"""
        strength = self.ai_denoise_strength.get()
        
        # Chuy·ªÉn ƒë·ªïi sang float32
        img_float = image.astype(np.float32) / 255.0
        
        # √Åp d·ª•ng BM3D-like denoising
        denoised = cv2.fastNlMeansDenoisingColored(image, None, 
                                                   h=strength*10, 
                                                   hColor=strength*10, 
                                                   templateWindowSize=7, 
                                                   searchWindowSize=21)
        
        # Wavelet denoising
        from skimage.restoration import denoise_wavelet
        denoised_wavelet = denoise_wavelet(img_float, method='BayesShrink', 
                                          mode='soft', rescale_sigma=True)
        denoised_wavelet = (denoised_wavelet * 255).astype(np.uint8)
        
        # K·∫øt h·ª£p hai ph∆∞∆°ng ph√°p
        result = cv2.addWeighted(denoised, 0.6, denoised_wavelet, 0.4, 0)
        
        # Edge-preserving filter
        result = cv2.edgePreservingFilter(result, flags=2, sigma_s=50, sigma_r=0.4)
        
        return result
    
    def ai_deblur_advanced(self, image):
        """Kh·ª≠ m·ªù AI n√¢ng cao"""
        kernel_type = self.deblur_kernel.get()
        
        # T·∫°o kernel d·ª±a tr√™n lo·∫°i blur
        if kernel_type == "Gaussian":
            kernel = cv2.getGaussianKernel(15, 3)
            kernel = kernel @ kernel.T
        elif kernel_type == "Motion":
            kernel = np.zeros((15, 15))
            kernel[7, :] = 1
            kernel = kernel / 15
        elif kernel_type == "Defocus":
            kernel = np.zeros((15, 15))
            y, x = np.ogrid[-7:8, -7:8]
            mask = x**2 + y**2 <= 7**2
            kernel[mask] = 1
            kernel = kernel / np.sum(kernel)
        else:  # Adaptive
            # ∆Ø·ªõc t√≠nh kernel t·ª´ ·∫£nh
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            kernel = restoration.unsupervised_wiener(gray, gray)[1]
        
        # Wiener deconvolution
        deblurred_channels = []
        for i in range(3):
            channel = image[:, :, i]
            deblurred = restoration.wiener(channel, kernel, balance=0.1)
            deblurred_channels.append(deblurred)
        
        deblurred = np.stack(deblurred_channels, axis=2)
        deblurred = np.clip(deblurred * 255, 0, 255).astype(np.uint8)
        
        # Unsharp masking th√¥ng minh
        gaussian = cv2.GaussianBlur(image, (0, 0), 2.0)
        unsharp = cv2.addWeighted(image, 1.5, gaussian, -0.5, 0)
        
        # K·∫øt h·ª£p k·∫øt qu·∫£
        result = cv2.addWeighted(deblurred, 0.7, unsharp, 0.3, 0)
        
        return np.clip(result, 0, 255).astype(np.uint8)
    
    def ai_super_resolution(self, image):
        """Super Resolution AI ti√™n ti·∫øn"""
        scale = int(self.scale_factor.get()[0])
        
        h, w = image.shape[:2]
        
        # EDSR-inspired super resolution
        # B∆∞·ªõc 1: Upscale b·∫±ng LANCZOS4
        new_h, new_w = h * scale, w * scale
        upscaled = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
        
        # B∆∞·ªõc 2: Residual enhancement
        # T·∫°o high-frequency features
        blur = cv2.GaussianBlur(upscaled, (5, 5), 1.0)
        high_freq = cv2.subtract(upscaled, blur)
        
        # TƒÉng c∆∞·ªùng high-frequency
        enhanced_hf = cv2.addWeighted(high_freq, 2.0, high_freq, 0, 0)
        
        # K·∫øt h·ª£p l·∫°i
        result = cv2.add(blur, enhanced_hf)
        
        # B∆∞·ªõc 3: Edge enhancement
        # Sobel edge detection
        gray = cv2.cvtColor(result, cv2.COLOR_RGB2GRAY)
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        edges = np.sqrt(sobelx**2 + sobely**2)
        
        # TƒÉng c∆∞·ªùng edges
        edges_normalized = (edges / edges.max() * 255).astype(np.uint8)
        edges_colored = cv2.applyColorMap(edges_normalized, cv2.COLORMAP_JET)
        
        # Blend v·ªõi ·∫£nh g·ªëc
        result = cv2.addWeighted(result, 0.9, edges_colored, 0.1, 0)
        
        # B∆∞·ªõc 4: Adaptive sharpening
        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]) * 0.2
        sharpened = cv2.filter2D(result, -1, kernel)
        result = cv2.addWeighted(result, 0.8, sharpened, 0.2, 0)
        
        return np.clip(result, 0, 255).astype(np.uint8)
    
    def ai_color_restoration(self, image):
        """Kh√¥i ph·ª•c m√†u s·∫Øc AI"""
        strength = self.color_strength.get()
        
        # Chuy·ªÉn sang LAB color space
        lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        
        # TƒÉng c∆∞·ªùng k√™nh L (lightness)
        l = cv2.equalizeHist(l)
        
        # TƒÉng c∆∞·ªùng k√™nh A v√† B (chrominance)
        a = cv2.addWeighted(a, strength, a, 0, 0)
        b = cv2.addWeighted(b, strength, b, 0, 0)
        
        # K·∫øt h·ª£p l·∫°i
        enhanced_lab = cv2.merge([l, a, b])
        enhanced_rgb = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)
        
        # ƒêi·ªÅu ch·ªânh saturation
        hsv = cv2.cvtColor(enhanced_rgb, cv2.COLOR_RGB2HSV)
        h, s, v = cv2.split(hsv)
        s = cv2.addWeighted(s, strength, s, 0, 0)
        enhanced_hsv = cv2.merge([h, s, v])
        result = cv2.cvtColor(enhanced_hsv, cv2.COLOR_HSV2RGB)
        
        return np.clip(result, 0, 255).astype(np.uint8)
    
    def ai_structure_restoration(self, image):
        """Kh√¥i ph·ª•c c·∫•u tr√∫c AI"""
        strength = self.structure_strength.get()
        
        # Morphological operations ƒë·ªÉ kh√¥i ph·ª•c c·∫•u tr√∫c
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        
        # Opening ƒë·ªÉ lo·∫°i b·ªè noise nh·ªè
        opened = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
        
        # Closing ƒë·ªÉ l·∫•p ƒë·∫ßy gaps
        closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
        
        # Gradient morphology ƒë·ªÉ tƒÉng c∆∞·ªùng edges
        gradient = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel)
        
        # K·∫øt h·ª£p v·ªõi ·∫£nh g·ªëc
        result = cv2.addWeighted(closed, 1-strength, gradient, strength, 0)
        
        # Tophat ƒë·ªÉ tƒÉng c∆∞·ªùng chi ti·∫øt s√°ng
        tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)
        result = cv2.add(result, tophat)
        
        return np.clip(result, 0, 255).astype(np.uint8)
    
    def reset_parameters(self):
        """Reset t·∫•t c·∫£ tham s·ªë v·ªÅ m·∫∑c ƒë·ªãnh"""
        self.ai_denoise_strength.set(0.8)
        self.color_strength.set(1.2)
        self.structure_strength.set(0.6)
        self.deblur_kernel.set("Adaptive")
        self.scale_factor.set("2x")
        self.preset_mode.set("T·ª± ƒë·ªông")
    
    def process_image(self):
        """X·ª≠ l√Ω ·∫£nh theo c√°c t√πy ch·ªçn ƒë∆∞·ª£c ch·ªçn"""
        if self.original_image is None:
            messagebox.showwarning("C·∫£nh b√°o", "Vui l√≤ng ch·ªçn ·∫£nh tr∆∞·ªõc!")
            return
        
        # B·∫Øt ƒë·∫ßu processing
        self.progress.configure(mode='determinate')
        self.progress['value'] = 0
        
        # Ch·∫°y x·ª≠ l√Ω trong thread ri√™ng
        thread = threading.Thread(target=self._process_image_thread)
        thread.start()
    
    def _process_image_thread(self):
        """X·ª≠ l√Ω ·∫£nh trong thread ri√™ng"""
        try:
            result = self.original_image.copy()
            total_steps = 5
            current_step = 0
            
            # B∆∞·ªõc 1: AI Kh·ª≠ nhi·ªÖu
            if self.ai_denoise_var.get():
                self.root.after(0, lambda: self.update_progress(current_step/total_steps*100, "ƒêang kh·ª≠ nhi·ªÖu AI..."))
                result = self.advanced_ai_denoise(result)
                current_step += 1
            
            # B∆∞·ªõc 2: AI Kh·ª≠ m·ªù
            if self.ai_deblur_var.get():
                self.root.after(0, lambda: self.update_progress(current_step/total_steps*100, "ƒêang kh·ª≠ m·ªù AI..."))
                result = self.ai_deblur_advanced(result)
                current_step += 1
            
            # B∆∞·ªõc 3: Super Resolution
            if self.super_res_var.get():
                self.root.after(0, lambda: self.update_progress(current_step/total_steps*100, "ƒêang n√¢ng ƒë·ªô ph√¢n gi·∫£i..."))
                result = self.ai_super_resolution(result)
                current_step += 1
            
            # B∆∞·ªõc 4: Kh√¥i ph·ª•c m√†u s·∫Øc
            if self.color_restore_var.get():
                self.root.after(0, lambda: self.update_progress(current_step/total_steps*100, "ƒêang kh√¥i ph·ª•c m√†u s·∫Øc..."))
                result = self.ai_color_restoration(result)
                current_step += 1
            
            # B∆∞·ªõc 5: Kh√¥i ph·ª•c c·∫•u tr√∫c
            if self.structure_restore_var.get():
                self.root.after(0, lambda: self.update_progress(current_step/total_steps*100, "ƒêang kh√¥i ph·ª•c c·∫•u tr√∫c..."))
                result = self.ai_structure_restoration(result)
                current_step += 1
            
            self.processed_image = result
            
            # Ho√†n th√†nh
            self.root.after(0, lambda: self.update_progress(100, "Ho√†n th√†nh!"))
            self.root.after(0, self._update_ui_after_processing)
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("L·ªói", f"L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}"))
            self.root.after(0, lambda: self.update_progress(0, "L·ªói x·ª≠ l√Ω"))
    
    def update_progress(self, value, text):
        """C·∫≠p nh·∫≠t progress bar"""
        self.progress['value'] = value
        self.progress_label.config(text=text)
        self.root.update_idletasks()
    
    def _update_ui_after_processing(self):
        """C·∫≠p nh·∫≠t UI sau khi x·ª≠ l√Ω xong"""
        self.display_image(self.processed_image, self.processed_canvas)
        self.add_processing_info()
        messagebox.showinfo("Th√†nh c√¥ng", "X·ª≠ l√Ω ·∫£nh ho√†n t·∫•t!")
    
    def add_processing_info(self):
        """Th√™m th√¥ng tin v·ªÅ qu√° tr√¨nh x·ª≠ l√Ω"""
        info = "\n=== K·∫æT QU·∫¢ X·ª¨ L√ù ===\n"
        
        if self.ai_denoise_var.get():
            info += f"‚úì Kh·ª≠ nhi·ªÖu AI (C∆∞·ªùng ƒë·ªô: {self.ai_denoise_strength.get():.1f})\n"
        
        if self.ai_deblur_var.get():
            info += f"‚úì Kh·ª≠ m·ªù AI (Kernel: {self.deblur_kernel.get()})\n"
        
        if self.super_res_var.get():
            info += f"‚úì Super Resolution (T·ªâ l·ªá: {self.scale_factor.get()})\n"
        
        if self.color_restore_var.get():
            info += f"‚úì Kh√¥i ph·ª•c m√†u s·∫Øc (C∆∞·ªùng ƒë·ªô: {self.color_strength.get():.1f})\n"
        
        if self.structure_restore_var.get():
            info += f"‚úì Kh√¥i ph·ª•c c·∫•u tr√∫c (ƒê·ªô m·∫°nh: {self.structure_strength.get():.1f})\n"
        
        # T√≠nh to√°n ch·ªâ s·ªë ch·∫•t l∆∞·ª£ng
        if self.original_image is not None and self.processed_image is not None:
            psnr, ssim = self.calculate_quality_metrics()
            info += f"\n=== CH·ªà S·ªê CH·∫§T L∆Ø·ª¢NG ===\n"
            info += f"PSNR: {psnr:.2f} dB\n"
            info += f"SSIM: {ssim:.4f}\n"
        
        self.info_text.insert(tk.END, info)
        self.info_text.see(tk.END)
    
    def calculate_quality_metrics(self):
        """T√≠nh to√°n PSNR v√† SSIM"""
        from skimage.metrics import peak_signal_noise_ratio, structural_similarity
        
        # Resize processed image to match original if needed
        if self.processed_image.shape != self.original_image.shape:
            h, w = self.original_image.shape[:2]
            processed_resized = cv2.resize(self.processed_image, (w, h))
        else:
            processed_resized = self.processed_image
        
        # Convert to grayscale for SSIM calculation
        orig_gray = cv2.cvtColor(self.original_image, cv2.COLOR_RGB2GRAY)
        proc_gray = cv2.cvtColor(processed_resized, cv2.COLOR_RGB2GRAY)
        
        # Calculate PSNR
        psnr = peak_signal_noise_ratio(self.original_image, processed_resized)
        
        # Calculate SSIM
        ssim = structural_similarity(orig_gray, proc_gray)
        
        return psnr, ssim
    
    def save_image(self):
        """L∆∞u ·∫£nh ƒë√£ x·ª≠ l√Ω"""
        if self.processed_image is None:
            messagebox.showwarning("C·∫£nh b√°o", "Ch∆∞a c√≥ ·∫£nh ƒë∆∞·ª£c x·ª≠ l√Ω!")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="L∆∞u ·∫£nh",
            defaultextension=".png",
            filetypes=[("PNG files", "*.png"), ("JPEG files", "*.jpg"), ("All files", "*.*")]
        )
        
        if file_path:
            try:
                # Convert RGB to BGR for OpenCV
                bgr_image = cv2.cvtColor(self.processed_image, cv2.COLOR_RGB2BGR)
                cv2.imwrite(file_path, bgr_image)
                messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ l∆∞u ·∫£nh t·∫°i: {file_path}")
            except Exception as e:
                messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ l∆∞u ·∫£nh: {str(e)}")
    
    def detailed_comparison(self):
        """Hi·ªÉn th·ªã so s√°nh chi ti·∫øt"""
        if self.original_image is None or self.processed_image is None:
            messagebox.showwarning("C·∫£nh b√°o", "C·∫ßn c√≥ ·∫£nh g·ªëc v√† ·∫£nh ƒë√£ x·ª≠ l√Ω!")
            return
        
        # T·∫°o c·ª≠a s·ªï so s√°nh m·ªõi
        comparison_window = tk.Toplevel(self.root)
        comparison_window.title("So s√°nh Chi ti·∫øt")
        comparison_window.geometry("1400x800")
        
        # Frame cho histogram
        hist_frame = ttk.LabelFrame(comparison_window, text="Histogram So s√°nh", padding="10")
        hist_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # T·∫°o matplotlib figure
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 8))
        
        # Hi·ªÉn th·ªã ·∫£nh g·ªëc
        ax1.imshow(self.original_image)
        ax1.set_title('·∫¢nh G·ªëc')
        ax1.axis('off')
        
        # Hi·ªÉn th·ªã ·∫£nh ƒë√£ x·ª≠ l√Ω
        processed_display = self.processed_image
        if self.processed_image.shape != self.original_image.shape:
            h, w = self.original_image.shape[:2]
            processed_display = cv2.resize(self.processed_image, (w, h))
        
        ax2.imshow(processed_display)
        ax2.set_title('·∫¢nh Sau X·ª≠ l√Ω')
        ax2.axis('off')
        
        # Histogram ·∫£nh g·ªëc
        for i, color in enumerate(['red', 'green', 'blue']):
            hist = cv2.calcHist([self.original_image], [i], None, [256], [0, 256])
            ax3.plot(hist, color=color, alpha=0.7)
        ax3.set_title('Histogram ·∫¢nh G·ªëc')
        ax3.set_xlabel('Pixel Value')
        ax3.set_ylabel('Frequency')
        
        # Histogram ·∫£nh ƒë√£ x·ª≠ l√Ω
        for i, color in enumerate(['red', 'green', 'blue']):
            hist = cv2.calcHist([processed_display], [i], None, [256], [0, 256])
            ax4.plot(hist, color=color, alpha=0.7)
        ax4.set_title('Histogram ·∫¢nh Sau X·ª≠ l√Ω')
        ax4.set_xlabel('Pixel Value')
        ax4.set_ylabel('Frequency')
        
        plt.tight_layout()
        
        # Nh√∫ng matplotlib v√†o tkinter
        canvas = FigureCanvasTkinter(fig, hist_frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        # Th√™m th√¥ng tin chi ti·∫øt
        detail_frame = ttk.LabelFrame(comparison_window, text="Th√¥ng tin Chi ti·∫øt", padding="10")
        detail_frame.pack(fill=tk.X, padx=10, pady=(0, 10))
        
        detail_text = tk.Text(detail_frame, height=8, width=100)
        detail_text.pack(fill=tk.BOTH, expand=True)
        
        # T√≠nh to√°n chi ti·∫øt
        psnr, ssim = self.calculate_quality_metrics()
        
        detail_info = f"=== PH√ÇN T√çCH CHI TI·∫æT ===\n"
        detail_info += f"PSNR: {psnr:.2f} dB (>30dB = T·ªët, >40dB = R·∫•t t·ªët)\n"
        detail_info += f"SSIM: {ssim:.4f} (>0.8 = T·ªët, >0.9 = R·∫•t t·ªët)\n"
        
        # Ph√¢n t√≠ch histogram
        orig_mean = np.mean(self.original_image)
        proc_mean = np.mean(processed_display)
        orig_std = np.std(self.original_image)
        proc_std = np.std(processed_display)
        
        detail_info += f"\n=== TH·ªêNG K√ä PIXEL ===\n"
        detail_info += f"ƒê·ªô s√°ng trung b√¨nh: {orig_mean:.1f} ‚Üí {proc_mean:.1f}\n"
        detail_info += f"ƒê·ªô l·ªách chu·∫©n: {orig_std:.1f} ‚Üí {proc_std:.1f}\n"
        detail_info += f"Thay ƒë·ªïi t∆∞∆°ng ph·∫£n: {((proc_std - orig_std) / orig_std * 100):.1f}%\n"
        
        detail_text.insert(tk.END, detail_info)
    
    def batch_process(self):
        """X·ª≠ l√Ω h√†ng lo·∫°t ·∫£nh"""
        input_folder = filedialog.askdirectory(title="Ch·ªçn th∆∞ m·ª•c ·∫£nh ƒë·∫ßu v√†o")
        if not input_folder:
            return
        
        output_folder = filedialog.askdirectory(title="Ch·ªçn th∆∞ m·ª•c ƒë·∫ßu ra")
        if not output_folder:
            return
        
        # T√¨m t·∫•t c·∫£ ·∫£nh trong th∆∞ m·ª•c
        image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')
        image_files = []
        
        for file in os.listdir(input_folder):
            if file.lower().endswith(image_extensions):
                image_files.append(file)
        
        if not image_files:
            messagebox.showwarning("C·∫£nh b√°o", "Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o trong th∆∞ m·ª•c!")
            return
        
        # T·∫°o c·ª≠a s·ªï progress cho batch processing
        batch_window = tk.Toplevel(self.root)
        batch_window.title("X·ª≠ l√Ω H√†ng lo·∫°t")
        batch_window.geometry("600x300")
        
        ttk.Label(batch_window, text=f"ƒêang x·ª≠ l√Ω {len(image_files)} ·∫£nh...").pack(pady=10)
        
        batch_progress = ttk.Progressbar(batch_window, mode='determinate', length=500)
        batch_progress.pack(pady=10)
        
        batch_label = ttk.Label(batch_window, text="Chu·∫©n b·ªã...")
        batch_label.pack(pady=5)
        
        batch_text = tk.Text(batch_window, height=10, width=70)
        batch_text.pack(pady=10, padx=10, fill=tk.BOTH, expand=True)
        
        # Ch·∫°y batch processing trong thread ri√™ng
        def batch_process_thread():
            try:
                total_files = len(image_files)
                processed_count = 0
                
                for i, filename in enumerate(image_files):
                    input_path = os.path.join(input_folder, filename)
                    output_path = os.path.join(output_folder, f"restored_{filename}")
                    
                    # C·∫≠p nh·∫≠t progress
                    progress = (i / total_files) * 100
                    batch_window.after(0, lambda p=progress, f=filename: [
                        batch_progress.config(value=p),
                        batch_label.config(text=f"ƒêang x·ª≠ l√Ω: {f}")
                    ])
                    
                    try:
                        # Load v√† x·ª≠ l√Ω ·∫£nh
                        image = cv2.imread(input_path)
                        if image is None:
                            continue
                        
                        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                        
                        # √Åp d·ª•ng c√°c b∆∞·ªõc x·ª≠ l√Ω
                        result = image_rgb.copy()
                        
                        if self.ai_denoise_var.get():
                            result = self.advanced_ai_denoise(result)
                        
                        if self.ai_deblur_var.get():
                            result = self.ai_deblur_advanced(result)
                        
                        if self.super_res_var.get():
                            result = self.ai_super_resolution(result)
                        
                        if self.color_restore_var.get():
                            result = self.ai_color_restoration(result)
                        
                        if self.structure_restore_var.get():
                            result = self.ai_structure_restoration(result)
                        
                        # L∆∞u k·∫øt qu·∫£
                        result_bgr = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)
                        cv2.imwrite(output_path, result_bgr)
                        
                        processed_count += 1
                        batch_window.after(0, lambda f=filename: batch_text.insert(tk.END, f"‚úì Ho√†n th√†nh: {f}\n"))
                        
                    except Exception as e:
                        batch_window.after(0, lambda f=filename, err=str(e): batch_text.insert(tk.END, f"‚úó L·ªói {f}: {err}\n"))
                
                # Ho√†n th√†nh
                batch_window.after(0, lambda: [
                    batch_progress.config(value=100),
                    batch_label.config(text=f"Ho√†n th√†nh! ƒê√£ x·ª≠ l√Ω {processed_count}/{total_files} ·∫£nh"),
                    batch_text.insert(tk.END, f"\n=== HO√ÄN TH√ÄNH ===\nƒê√£ x·ª≠ l√Ω: {processed_count}/{total_files} ·∫£nh\n")
                ])
                
            except Exception as e:
                batch_window.after(0, lambda: messagebox.showerror("L·ªói", f"L·ªói x·ª≠ l√Ω h√†ng lo·∫°t: {str(e)}"))
        
        thread = threading.Thread(target=batch_process_thread)
        thread.start()
    
    def enhance_with_ai_models(self, image):
        """T√≠ch h·ª£p c√°c m√¥ h√¨nh AI ti√™n ti·∫øn (placeholder for future implementation)"""
        # ƒê√¢y l√† n∆°i c√≥ th·ªÉ t√≠ch h·ª£p c√°c m√¥ h√¨nh AI nh∆∞:
        # - Real-ESRGAN
        # - SwinIR
        # - BSRGAN
        # - CodeFormer (cho ·∫£nh ch√¢n dung)
        
        # Hi·ªán t·∫°i s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t x·ª≠ l√Ω ·∫£nh truy·ªÅn th·ªëng
        # Trong t∆∞∆°ng lai c√≥ th·ªÉ load pre-trained models
        
        pass
    
    def create_processing_pipeline(self):
        """T·∫°o pipeline x·ª≠ l√Ω t√πy ch·ªânh"""
        pipeline = []
        
        if self.ai_denoise_var.get():
            pipeline.append(("AI Denoise", self.advanced_ai_denoise))
        
        if self.ai_deblur_var.get():
            pipeline.append(("AI Deblur", self.ai_deblur_advanced))
        
        if self.super_res_var.get():
            pipeline.append(("Super Resolution", self.ai_super_resolution))
        
        if self.color_restore_var.get():
            pipeline.append(("Color Restoration", self.ai_color_restoration))
        
        if self.structure_restore_var.get():
            pipeline.append(("Structure Restoration", self.ai_structure_restoration))
        
        return pipeline
    
    def export_processing_report(self):
        """Xu·∫•t b√°o c√°o x·ª≠ l√Ω"""
        if self.original_image is None or self.processed_image is None:
            messagebox.showwarning("C·∫£nh b√°o", "C·∫ßn c√≥ ·∫£nh g·ªëc v√† ·∫£nh ƒë√£ x·ª≠ l√Ω!")
            return
        
        report_path = filedialog.asksaveasfilename(
            title="L∆∞u b√°o c√°o",
            defaultextension=".txt",
            filetypes=[("Text files", "*.txt"), ("All files", "*.*")]
        )
        
        if report_path:
            try:
                psnr, ssim = self.calculate_quality_metrics()
                
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write("=== B√ÅO C√ÅO X·ª¨ L√ù ·∫¢NH AI ===\n")
                    f.write(f"Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"·∫¢nh g·ªëc: {self.current_image_path}\n")
                    f.write(f"K√≠ch th∆∞·ªõc g·ªëc: {self.original_image.shape}\n")
                    f.write(f"K√≠ch th∆∞·ªõc sau x·ª≠ l√Ω: {self.processed_image.shape}\n\n")
                    
                    f.write("=== C√ÅC B∆Ø·ªöC X·ª¨ L√ù ===\n")
                    if self.ai_denoise_var.get():
                        f.write(f"- AI Kh·ª≠ nhi·ªÖu (C∆∞·ªùng ƒë·ªô: {self.ai_denoise_strength.get()})\n")
                    if self.ai_deblur_var.get():
                        f.write(f"- AI Kh·ª≠ m·ªù (Kernel: {self.deblur_kernel.get()})\n")
                    if self.super_res_var.get():
                        f.write(f"- Super Resolution (T·ªâ l·ªá: {self.scale_factor.get()})\n")
                    if self.color_restore_var.get():
                        f.write(f"- Kh√¥i ph·ª•c m√†u s·∫Øc (C∆∞·ªùng ƒë·ªô: {self.color_strength.get()})\n")
                    if self.structure_restore_var.get():
                        f.write(f"- Kh√¥i ph·ª•c c·∫•u tr√∫c (ƒê·ªô m·∫°nh: {self.structure_strength.get()})\n")
                    
                    f.write(f"\n=== CH·ªà S·ªê CH·∫§T L∆Ø·ª¢NG ===\n")
                    f.write(f"PSNR: {psnr:.2f} dB\n")
                    f.write(f"SSIM: {ssim:.4f}\n")
                    
                    f.write(f"\n=== ƒê√ÅNH GI√Å ===\n")
                    if psnr > 30:
                        f.write("- Ch·∫•t l∆∞·ª£ng PSNR: T·ªët\n")
                    elif psnr > 25:
                        f.write("- Ch·∫•t l∆∞·ª£ng PSNR: Trung b√¨nh\n")
                    else:
                        f.write("- Ch·∫•t l∆∞·ª£ng PSNR: C·∫ßn c·∫£i thi·ªán\n")
                    
                    if ssim > 0.8:
                        f.write("- Ch·∫•t l∆∞·ª£ng SSIM: T·ªët\n")
                    elif ssim > 0.6:
                        f.write("- Ch·∫•t l∆∞·ª£ng SSIM: Trung b√¨nh\n")
                    else:
                        f.write("- Ch·∫•t l∆∞·ª£ng SSIM: C·∫ßn c·∫£i thi·ªán\n")
                
                messagebox.showinfo("Th√†nh c√¥ng", f"ƒê√£ xu·∫•t b√°o c√°o t·∫°i: {report_path}")
                
            except Exception as e:
                messagebox.showerror("L·ªói", f"Kh√¥ng th·ªÉ xu·∫•t b√°o c√°o: {str(e)}")

# Th√™m import c·∫ßn thi·∫øt
from datetime import datetime

def main():
    """H√†m main ƒë·ªÉ ch·∫°y ·ª©ng d·ª•ng"""
    root = tk.Tk()
    app = AdvancedImageRestorationApp(root)
    
    # Th√™m menu bar
    menubar = tk.Menu(root)
    root.config(menu=menubar)
    
    # File menu
    file_menu = tk.Menu(menubar, tearoff=0)
    menubar.add_cascade(label="File", menu=file_menu)
    file_menu.add_command(label="M·ªü ·∫£nh", command=app.load_image)
    file_menu.add_command(label="L∆∞u ·∫£nh", command=app.save_image)
    file_menu.add_separator()
    file_menu.add_command(label="X·ª≠ l√Ω h√†ng lo·∫°t", command=app.batch_process)
    file_menu.add_separator()
    file_menu.add_command(label="Tho√°t", command=root.quit)
    
    # Tools menu
    tools_menu = tk.Menu(menubar, tearoff=0)
    menubar.add_cascade(label="C√¥ng c·ª•", menu=tools_menu)
    tools_menu.add_command(label="So s√°nh chi ti·∫øt", command=app.detailed_comparison)
    tools_menu.add_command(label="Xu·∫•t b√°o c√°o", command=app.export_processing_report)
    tools_menu.add_command(label="Reset tham s·ªë", command=app.reset_parameters)
    
    # Help menu
    help_menu = tk.Menu(menubar, tearoff=0)
    menubar.add_cascade(label="Tr·ª£ gi√∫p", menu=help_menu)
    help_menu.add_command(label="H∆∞·ªõng d·∫´n", command=lambda: messagebox.showinfo(
        "H∆∞·ªõng d·∫´n", 
        "1. Ch·ªçn ·∫£nh t·ª´ menu File\n"
        "2. Ch·ªçn ch·∫ø ƒë·ªô x·ª≠ l√Ω ph√π h·ª£p\n"
        "3. ƒêi·ªÅu ch·ªânh c√°c tham s·ªë\n"
        "4. Nh·∫•n 'X·ª≠ l√Ω AI' ƒë·ªÉ b·∫Øt ƒë·∫ßu\n"
        "5. So s√°nh v√† l∆∞u k·∫øt qu·∫£\n\n"
        "Ch·∫ø ƒë·ªô:\n"
        "- T·ª± ƒë·ªông: Ph√π h·ª£p v·ªõi h·∫ßu h·∫øt ·∫£nh\n"
        "- ·∫¢nh c≈©: T·ªëi ∆∞u cho ·∫£nh scan c≈©\n"
        "- T√†i li·ªáu: T·ªëi ∆∞u cho vƒÉn b·∫£n\n"
        "- ·∫¢nh ch√¢n dung: T·ªëi ∆∞u cho ·∫£nh ng∆∞·ªùi"
    ))
    help_menu.add_command(label="V·ªÅ ch∆∞∆°ng tr√¨nh", command=lambda: messagebox.showinfo(
        "V·ªÅ ch∆∞∆°ng tr√¨nh", 
        "Ch∆∞∆°ng tr√¨nh Kh√¥i ph·ª•c ·∫¢nh AI N√¢ng cao\n"
        "Phi√™n b·∫£n: 1.0\n"
        "T√°c gi·∫£: AI Assistant\n\n"
        "T√≠nh nƒÉng:\n"
        "‚úì Kh·ª≠ nhi·ªÖu AI\n"
        "‚úì Kh·ª≠ m·ªù th√¥ng minh\n"
        "‚úì Super Resolution\n"
        "‚úì Kh√¥i ph·ª•c m√†u s·∫Øc\n"
        "‚úì Kh√¥i ph·ª•c c·∫•u tr√∫c\n"
        "‚úì X·ª≠ l√Ω h√†ng lo·∫°t\n"
        "‚úì ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng PSNR/SSIM"
    ))
    
    root.mainloop()

if __name__ == "__main__":
    main()